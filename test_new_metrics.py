#!/usr/bin/env python3
"""
æµ‹è¯•æ–°çš„æ”»å‡»è¯„ä¼°æŒ‡æ ‡ç³»ç»Ÿ
"""

import torch
import numpy as np
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

from utils.attack_metrics import calculate_attack_metrics, print_attack_metrics
from utils.results_saver import save_attack_results, load_attack_results, print_results_summary

def test_attack_metrics():
    """æµ‹è¯•æ”»å‡»è¯„ä¼°æŒ‡æ ‡è®¡ç®—"""
    print("=== æµ‹è¯•æ”»å‡»è¯„ä¼°æŒ‡æ ‡è®¡ç®— ===")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size = 100
    num_classes = 3
    
    # æ¨¡æ‹Ÿé¢„æµ‹æ¦‚ç‡ (logits)
    predictions = torch.randn(batch_size, num_classes)
    # æ·»åŠ ä¸€äº›å™ªå£°ï¼Œä½¿å¾—é¢„æµ‹ä¸æ˜¯å®Œå…¨éšæœºçš„
    predictions[:50, 0] += 2.0  # å‰50ä¸ªæ ·æœ¬æ›´å¯èƒ½æ˜¯ç±»åˆ«0
    predictions[50:80, 1] += 2.0  # æ¥ä¸‹æ¥30ä¸ªæ ·æœ¬æ›´å¯èƒ½æ˜¯ç±»åˆ«1  
    predictions[80:, 2] += 2.0  # æœ€å20ä¸ªæ ·æœ¬æ›´å¯èƒ½æ˜¯ç±»åˆ«2
    
    # åˆ›å»ºå¯¹åº”çš„çœŸå®æ ‡ç­¾
    targets = torch.zeros(batch_size, dtype=torch.long)
    targets[:50] = 0
    targets[50:80] = 1
    targets[80:] = 2
    
    # è®¡ç®—æ”»å‡»æŒ‡æ ‡
    metrics = calculate_attack_metrics(predictions, targets, num_classes)
    
    # æ‰“å°ç»“æœ
    print_attack_metrics(metrics, 'Test_Attack', 'test_dataset')
    
    # éªŒè¯æŒ‡æ ‡çš„åˆç†æ€§
    assert 0 <= metrics['acc'] <= 100, "å‡†ç¡®ç‡åº”è¯¥åœ¨0-100ä¹‹é—´"
    assert 0 <= metrics['top1_acc'] <= 100, "Top-1å‡†ç¡®ç‡åº”è¯¥åœ¨0-100ä¹‹é—´"
    assert 0 <= metrics['top5_acc'] <= 100, "Top-5å‡†ç¡®ç‡åº”è¯¥åœ¨0-100ä¹‹é—´"
    assert 0 <= metrics['f1_score'] <= 100, "F1åˆ†æ•°åº”è¯¥åœ¨0-100ä¹‹é—´"
    assert metrics['top5_acc'] >= metrics['top1_acc'], "Top-5å‡†ç¡®ç‡åº”è¯¥å¤§äºç­‰äºTop-1å‡†ç¡®ç‡"
    
    print("âœ… æ”»å‡»è¯„ä¼°æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡!")
    return metrics

def test_results_saver():
    """æµ‹è¯•ç»“æœä¿å­˜å’ŒåŠ è½½"""
    print("\n=== æµ‹è¯•ç»“æœä¿å­˜å’ŒåŠ è½½ ===")
    
    # åˆ›å»ºæµ‹è¯•æŒ‡æ ‡
    test_metrics = {
        'acc': 85.5,
        'top1_acc': 85.5,
        'top5_acc': 95.0,
        'f1_score': 82.3
    }
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_results_file = 'result/test_results.csv'
    save_attack_results('Test_Algorithm', 'test_dataset', test_metrics, test_results_file)
    
    # åŠ è½½å¹¶éªŒè¯ç»“æœ
    df = load_attack_results(test_results_file)
    assert len(df) > 0, "åº”è¯¥èƒ½åŠ è½½åˆ°ç»“æœæ•°æ®"
    
    # éªŒè¯ä¿å­˜çš„æ•°æ®
    test_row = df[(df['algorithm'] == 'Test_Algorithm') & (df['dataset'] == 'test_dataset')]
    assert len(test_row) == 1, "åº”è¯¥æ‰¾åˆ°ä¸€æ¡æµ‹è¯•è®°å½•"
    
    saved_acc = float(test_row['attack_acc'].values[0])
    assert abs(saved_acc - test_metrics['acc']) < 0.1, "ä¿å­˜çš„å‡†ç¡®ç‡åº”è¯¥ä¸åŸå§‹å€¼æ¥è¿‘"
    
    print("âœ… ç»“æœä¿å­˜å’ŒåŠ è½½æµ‹è¯•é€šè¿‡!")
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    if os.path.exists(test_results_file):
        os.remove(test_results_file)

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\n=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
    
    # æµ‹è¯•å®Œç¾é¢„æµ‹
    perfect_predictions = torch.tensor([[10.0, 0.0], [0.0, 10.0], [10.0, 0.0]])
    perfect_targets = torch.tensor([0, 1, 0])
    perfect_metrics = calculate_attack_metrics(perfect_predictions, perfect_targets, 2)
    
    assert perfect_metrics['acc'] == 100.0, "å®Œç¾é¢„æµ‹çš„å‡†ç¡®ç‡åº”è¯¥æ˜¯100%"
    assert perfect_metrics['f1_score'] == 100.0, "å®Œç¾é¢„æµ‹çš„F1åˆ†æ•°åº”è¯¥æ˜¯100%"
    
    # æµ‹è¯•éšæœºé¢„æµ‹
    random_predictions = torch.randn(50, 5)  # 5ç±»éšæœºé¢„æµ‹
    random_targets = torch.randint(0, 5, (50,))
    random_metrics = calculate_attack_metrics(random_predictions, random_targets, 5)
    
    # éšæœºé¢„æµ‹çš„å‡†ç¡®ç‡åº”è¯¥å¤§çº¦åœ¨20%å·¦å³ï¼ˆ1/5ï¼‰
    assert 5 <= random_metrics['acc'] <= 40, f"éšæœºé¢„æµ‹å‡†ç¡®ç‡å¼‚å¸¸: {random_metrics['acc']}"
    
    print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡!")

def test_compatibility_with_existing_code():
    """æµ‹è¯•ä¸ç°æœ‰ä»£ç çš„å…¼å®¹æ€§"""
    print("\n=== æµ‹è¯•ä¸ç°æœ‰ä»£ç å…¼å®¹æ€§ ===")
    
    try:
        # æµ‹è¯•å¯¼å…¥æ˜¯å¦æˆåŠŸ
        from utils.attack_metrics import evaluate_attack_model
        from utils.results_saver import save_attack_results
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ!")
        
        # æµ‹è¯•results.csvæ ¼å¼
        with open('result/results.csv', 'r') as f:
            header = f.readline().strip()
            expected_header = "algorithm,dataset,attack_acc,attack_top1,attack_top5,attack_f1"
            assert header == expected_header, f"CSVæ ¼å¼ä¸æ­£ç¡®: {header}"
        print("âœ… Results.csvæ ¼å¼æ­£ç¡®!")
        
    except Exception as e:
        print(f"âŒ å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        raise

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•æ–°çš„æ”»å‡»è¯„ä¼°æŒ‡æ ‡ç³»ç»Ÿ...\n")
    
    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        test_attack_metrics()
        test_results_saver()
        test_edge_cases()
        test_compatibility_with_existing_code()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ–°çš„è¯„ä¼°ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
        print("\nğŸ“‹ æ€»ç»“:")
        print("âœ… æ”»å‡»è¯„ä¼°æŒ‡æ ‡è®¡ç®—æ­£ç¡®")
        print("âœ… ç»“æœä¿å­˜å’ŒåŠ è½½åŠŸèƒ½æ­£å¸¸")
        print("âœ… è¾¹ç•Œæƒ…å†µå¤„ç†æ­£ç¡®")
        print("âœ… ä¸ç°æœ‰ä»£ç å…¼å®¹")
        
        print("\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œæ”»å‡»è„šæœ¬æµ‹è¯•æ–°çš„è¯„ä¼°æŒ‡æ ‡:")
        print("   python3 passive_lia.py --dataset bcw --epochs 1")
        print("   python3 active_lia.py --dataset bcw --epochs 1")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
