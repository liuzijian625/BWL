# “边界漫游学习 (BWL)” 实现指南 (method.md)

本文档为“边界漫游学习 (Boundary-Wandering Learning, BWL)”框架提供了一份全面的实现指南。BWL是一种针对垂直联邦学习 (VFL) 中标签推断攻击的新型防御机制。

## 1. 核心思想概述

BWL框架的核心防御范式是从“控制信息含量”转变为“重塑几何结构”。它并非简单地隐藏或压缩信息，而是主动地、系统性地瓦解攻击者赖以推断的嵌入空间几何结构。

该框架通过两个相辅相成的核心组件实现这一目标：
1.  **边界漫游损失 ($L_{bw}$):** 一种创新的损失函数，其原则是“同类相斥”。它强制同一类别的样本嵌入在角度上彼此远离，从而切断嵌入相似度与标签一致性之间的强关联。
2.  **影子顶层模型 (Shadow Top Model) 架构:** 一种新颖的**双轨训练架构**，在主动方（防御者）处部署。该架构通过创建两个并行的顶层模型，实现了“联邦混淆空间”与“本地保真空间”的彻底解耦，从而解决了传统的隐私-效用冲突问题。

## 2. 系统设置与前提条件

-   **VFL场景:** 一个标准的双方垂直联邦学习设置。
    -   **参与方A (攻击者):** 持有部分特征 $X_A$ 的被动方，其行为模式为“诚实但好奇”。
    -   **参与方B (防御者):** 持有另一部分特征 $X_B$ 和全部私有标签 $Y$ 的主动方。**防御方同时扮演服务器角色**，负责所有顶层模型的计算和梯度分发。
-   **模型结构:**
    -   **参与方A:** 拥有一个底层模型 $M_A$。
    -   **参与方B (防御者):** 部署特殊的双轨架构，包含：
        -   两个底层模型：$M_{public}$ 和 $M_{private}$。
        -   两个顶层模型：$M_{shadow\_top}$ (影子模型) 和 $M_{main\_top}$ (主模型/保真模型)。

## 3. 核心组件实现

### 3.1. 防御方的双轨架构

在训练开始前，防御方 (参与方B) 需要在本地构建一个包含两个并行计算轨道的复杂架构。

#### 步骤 1: 特征划分

防御者必须首先在本地将其特征 $X_B$ 划分为两个互不相交的集合：
-   **公开特征 ($x_{public}$):** 与标签相关性较弱的一部分特征。
-   **私有特征 ($x_{private}$):** 与标签高度相关的一部分特征。

**实现要点:**
-   该划分是一个在VFL训练开始前完成的本地预处理步骤。
-   可以使用标准的特征选择技术来完成，例如计算**互信息**或使用**特征重要性**排序。
-   私有特征与公开特征的比例是一个重要的超参数，推荐从10%-30%的最具信息量的特征作为私有特征开始尝试。

#### 步骤 2: 模型实例化

防御者需要在本地实例化四组模型：
1.  **公开底层模型 ($M_{public}$):** 输入为**公开特征** $x_{public}$，输出为公开嵌入 $E_{public}$。该模型的更新受联邦混淆轨道影响。
2.  **私有底层模型 ($M_{private}$):** 输入为**私有特征** $x_{private}$，输出为私有嵌入 $E_{private}$。该模型的更新仅受本地保真轨道影响。
3.  **影子顶层模型 ($M_{shadow\_top}$):** 这是**对外交互的模型**。它接收 $E_A$ 和 $E_{public}$，并基于包含 $L_{bw}$ 的损失进行计算，负责生成对外分发的梯度。
4.  **主顶层模型 ($M_{main\_top}$):** 这是**纯本地的模型**。它接收 $E_A$, $E_{public}$ 和 $E_{private}$，并基于标准的交叉熵损失进行计算，其梯度仅用于更新私有底层模型。

### 3.2. 边界漫游损失 ($L_{bw}$)

该损失函数在**联邦混淆轨道**中，由防御者的**影子顶层模型**计算。计算对象是**从防御者自己公开底层模型产生的嵌入 $E_{public}$**。

**目标:** 最大化同一批次内、同类别样本嵌入之间的角度距离。在基于最小化的优化框架中，这等价于最小化它们之间的余弦相似度。

**数学公式:**
$$L_{bw} = \frac{1}{N_{pairs}} \sum_{\text{类别 } k} \sum_{i, j \in \mathcal{C}_k, i \neq j} \left( \frac{z_i}{\|z_i\|} \cdot \frac{z_j}{\|z_j\|} \right)$$
其中，$z_i$ 和 $z_j$ 是来自同一批次内、同一类别 $\mathcal{C}_k$ 的两个不同的公开嵌入向量 $E_{public}$。

**实现要点:**
-   在计算前，需要对该批次的所有 $E_{public}$ 向量进行L2归一化。
-   根据标签将归一化后的嵌入向量分组，对每个包含多个样本的组计算所有唯一对的余弦相似度之和。
-   为保证该损失的有效性，建议使用较大的批处理大小 (Batch Size)。

## 4. 完整训练流程 (单批次)

对于单个训练批次，防御者 (参与方B) 需要同时驱动两个并行的计算轨道。

#### **阶段一：前向传播与嵌入交换**

1.  **参与方A:** 计算其本地嵌入: $E_A = M_A(x_A)$，并将其发送给防御方B。
2.  **参与方B (防御者):**
    -   划分其批次特征: $x_B \rightarrow (x_{public}, x_{private})$。
    -   计算公开嵌入: $E_{public} = M_{public}(x_{public})$。
    -   计算私有嵌入: $E_{private} = M_{private}(x_{private})$。

#### **阶段二：双轨并行计算与反向传播**

防御方B在本地并行执行以下两个轨道：

---

**轨道一：联邦混淆轨道 (Shadow Track)**

*   **目标:** 构建一个对攻击者不友好的混淆空间，并更新所有参与方的公开部分模型 ($M_A$ 和 $M_{public}$)。
*   **流程:**
    1.  **输入:** 参与方A的嵌入 $E_A$ 和防御方自身的公开嵌入 $E_{public}$。
    2.  **融合:** $E_{fused\_shadow} = \text{Concat}(E_A, E_{public})$。
    3.  **前向传播:** 通过**影子顶层模型** $M_{shadow\_top}$ 计算预测 $p_{shadow}$。
    4.  **损失计算:** 计算复合损失 $L_{total} = \text{CrossEntropy}(p_{shadow}, y) + \alpha \cdot L_{bw}(E_{public}, y)$。
    5.  **梯度计算:** 基于 $L_{total}$ 计算关于输入的梯度 $\nabla E_A$ 和 $\nabla E_{public}$。
    6.  **梯度分发与更新:**
        -   将 $\nabla E_A$ 发送回参与方A，A据此更新其底层模型 $M_A$。
        -   在本地使用 $\nabla E_{public}$ 更新自身的**公开底层模型 $M_{public}$**。

---

**轨道二：本地保真轨道 (Main Track)**

*   **目标:** 在无干扰的理想环境下训练私有模型，以保证最终的预测性能。
*   **流程:**
    1.  **输入:** 参与方A的嵌入 $E_A$、防御方自身的公开嵌入 $E_{public}$ 和私有嵌入 $E_{private}$。
    2.  **融合:** $E_{fused\_main} = \text{Concat}(E_A, E_{public}, E_{private})$。
    3.  **前向传播:** 通过**主顶层模型** $M_{main\_top}$ 计算预测 $p_{main}$。
    4.  **损失计算:** 仅计算标准的交叉熵损失 $L_{local} = \text{CrossEntropy}(p_{main}, y)$。
    5.  **梯度计算与更新:** 基于 $L_{local}$ 进行反向传播，**梯度仅用于更新私有底层模型 $M_{private}$**。

---

## 5. 推理阶段

在模型训练完成后进行推理时，防御方**仅使用保真轨道**进行预测。
1.  A发送其推理数据的嵌入 $E_A$。
2.  B计算其推理数据的 $E_{public}$ 和 $E_{private}$。
3.  B将三者融合后，输入**主顶层模型 $M_{main\_top}$** 得到最终的高精度预测结果。

## 6. 超参数与配置

-   `alpha` ($\alpha$): 最核心的超参数，用于平衡主任务性能与隐私保护强度。
-   **特征划分比例:** 分配给私有特征与公开特征的比例。
-   **模型架构:** $M_{shadow\_top}$ 和 $M_{main\_top}$ 的架构可以相同也可以不同。通常设为相同以简化实现。
-   **批处理大小 (Batch Size):** 建议使用较大的批处理大小。